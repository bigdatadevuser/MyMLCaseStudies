# %% codecell
from __future__ import print_function
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
# %% codecell
training_data = pd.read_csv("./data/cs-training.csv")
# %% codecell
training_data.head()
# %% codecell
training_data.columns
# %% codecell
training_data = training_data.drop("Unnamed: 0",axis=1)
# %% codecell
training_data.head()
# %% codecell
training_data.columns = map(str.lower,training_data.columns)
# %% codecell
training_data.columns = training_data.columns.str.replace("-","")
# %% codecell
training_data.columns
# %% codecell
training_data[training_data.columns[1:]].describe()
# %% codecell
#Data set containes ~6% people info has default
training_data['seriousdlqin2yrs'].value_counts()/len(training_data['seriousdlqin2yrs']) * 100
# %% codecell
#Say it graphically ;below code can even obtained from googling ;)
sns.set()
sns.countplot(training_data['seriousdlqin2yrs']).set_title("Data Disribution")
ax = plt.gca()
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width()/2.,
            height + 2,
            '{:.2f}%'.format(100*(height/len(training_data['seriousdlqin2yrs']))),
            fontsize=14, ha='center', va='bottom')

sns.set(font_scale=1.5)
ax.set_xlabel("Labels for seriousdlqin2yrs attribute")
ax.set_ylabel("Numbers of records")
plt.show()
# %% codecell
#Look out for missing values now ;check which column has missing values ;

training_data.isnull().sum()
# %% codecell
#Say it graphically with bar plot;
x = training_data.columns
y = training_data.isnull().sum()
sns.set()
sns.barplot(x,y)
ax = plt.gca()
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width()/2.,
            height + 2,
            int(height),
            fontsize=14, ha='center', va='bottom')
sns.set(font_scale=1.5)
ax.set_xlabel("Data Attributes")
ax.set_ylabel("count of missing records for each attribute")
plt.xticks(rotation=90)
plt.show()
# %% codecell
#how will you deal with missing values then ? replace with mean ??

training_data_mean_replace = training_data.fillna(training_data.mean())

# %% codecell
training_data_mean_replace.isnull().sum()
# %% codecell
#Lets replace with mean now ;
training_data.fillna(training_data.mean(),inplace=True)
# %% codecell
#lets check the correlatioin between columns/variables;
training_data[training_data.columns[1:]].corr()
# %% codecell
#say it with graphics ; lets draw heat map and observe it ;
sns.set()
sns.set(font_scale=1.25)
sns.heatmap(training_data[training_data.columns[1:]].corr(),annot=True,fmt=".1f")
plt.show()

#We can see below have highly correlated ;
#NumberOfTime30-59DaysPastDueNotWorse -> NumberOfTimes90DaysLate
#NumberOfTime30-59DaysPastDueNotWorse -> NumberOfTime60-89DaysPastDueNotWorse

# %% codecell
#Till now what we have done steps  :

# 1. checked the training dataset
# 2. removed unnecessary columns
# 3. basic stats of all columns
# 4. check the distribution of target labels
# 5. check the missing values and their counts graphically;
# 6. replace the missing values with median : this is first try with missing values replacement
#there are other ways also to replace the missing values;
#7 : heatmap created to show the correlation

# %% codecell
#Now lets move to detecting the outliers
# There are variaous methods to detect outliers

# %% codecell
# Percentile based outlier detection
def percentile_based_outlier(data, threshold=95):
    diff = (100 - threshold) / 2.0
    (minval, maxval) = np.percentile(data, [diff, 100 - diff])    #return minval, maxval
    return ((data < minval) | (data > maxval))
# %% codecell

#Mi=0.6745(xiâˆ’x^)/MAD
def mad_based_outlier(points, threshold=3.5):
    median_y = np.median(points)
    median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in points])
    modified_z_scores = [0.6745 * (y - median_y) / median_absolute_deviation_y
                         for y in points]
    return np.abs(modified_z_scores) > threshold
# %% codecell
def std_div(data, threshold=3):
    std = data.std()
    mean = data.mean()
    isOutlier = []
    for val in data:
        if val/std > threshold:
            isOutlier.append(True)
        else:
            isOutlier.append(False)
    return isOutlier
#std_div(data=training_data.age)
# %% codecell
def outlierVote(data):
    x = percentile_based_outlier(data)
    y = mad_based_outlier(data)
    z = std_div(data)
    temp = list(zip(data.index, x, y, z))
    final = []
    for i in range(len(temp)):
        if temp[i].count(False) >= 2:
            final.append(False)
        else:
            final.append(True)
    return final
#outlierVote(data=training_data.age)
# %% codecell
def plotOutlier(x):
    fig, axes = plt.subplots(nrows=4)
    for ax, func in zip(axes, [percentile_based_outlier, mad_based_outlier, std_div, outlierVote]):
        sns.distplot(x, ax=ax, rug=True, hist=False)
        outliers = x[func(x)]
        ax.plot(outliers, np.zeros_like(outliers), 'ro', clip_on=False)
    kwargs = dict(y=0.95, x=0.05, ha='left', va='top', size=20)
    axes[0].set_title('Percentile-based Outliers', **kwargs)
    axes[1].set_title('MAD-based Outliers', **kwargs)
    axes[2].set_title('STD-based Outliers', **kwargs)
    axes[3].set_title('Majority vote based Outliers', **kwargs)
    fig.suptitle('Comparing Outlier Tests with n={}'.format(len(x)), size=20)
    fig = plt.gcf()
    fig.set_size_inches(15,10)
# %% codecell
#Lets plot outlier graphs based on all above 4 methods ; MAD;std , voting , percentile based

training_data.columns
# %% codecell

plotOutlier(training_data.revolvingutilizationofunsecuredlines.sample(1000))

# %% codecell
plotOutlier(training_data.age.sample(1000))
#Handle the outliers;
training_data.age.plot.box()
revNew = []
training_data.revolvingutilizationofunsecuredlines
for val in training_data.revolvingutilizationofunsecuredlines:
    if val <= 0.99999:
        revNew.append(val)
    else:
        revNew.append(0.99999)
training_data.revolvingutilizationofunsecuredlines = revNew

ageNew = []
for val in training_data.age:
    if val > 21:
        ageNew.append(val)
    else:
        ageNew.append(21)

training_data.age = ageNew

import collections
collections.Counter(training_data.numberoftime3059dayspastduenotworse)
New = []
med = training_data.numberoftime3059dayspastduenotworse.median()
for val in training_data.numberoftime3059dayspastduenotworse:
    if ((val == 98) | (val == 96)):
        New.append(med)
    else:
        New.append(val)

training_data.numberoftime3059dayspastduenotworse = New

def outlierRatio(data):
    functions = [percentile_based_outlier, mad_based_outlier, std_div, outlierVote]
    outlierDict = {}
    for func in functions:
        funcResult = func(data)
        count = 0
        for val in funcResult:
            if val == True:
                count += 1
        outlierDict[str(func)[10:].split()[0]] = [count, '{:.2f}%'.format((float(count)/len(data))*100)]
    return outlierDict

outlierRatio(training_data.debtratio)

plotOutlier(training_data.debtratio.sample(5000))
minUpperBound = min([val for (val, out) in zip(training_data.debtratio, mad_based_outlier(training_data.debtratio)) if out == True])
minUpperBound
newDebtRatio = []
for val in training_data.debtratio:
    if val > minUpperBound:
        newDebtRatio.append(minUpperBound)
    else:
        newDebtRatio.append(val)
training_data.debtratio = newDebtRatio

plotOutlier(training_data.monthlyincome.sample(1000))
def replaceOutlier(data, method = outlierVote, replace='median'):
    '''replace: median (auto)
                'minUpper' which is the upper bound of the outlier detection'''
    vote = outlierVote(data)
    x = pd.DataFrame(zip(data, vote), columns=['debt', 'outlier'])
    if replace == 'median':
        replace = x.debt.median()
    elif replace == 'minUpper':
        replace = min([val for (val, vote) in zip(data, vote) if vote == True])
        if replace < data.mean():
            return 'There are outliers lower than the sample mean'
    debtNew = []
    for i in range(x.shape[0]):
        if x.iloc[i][1] == True:
            debtNew.append(replace)
        else:
            debtNew.append(x.iloc[i][0])
    return debtNew
[vote for vote in outlierVote(training_data.monthlyincome) if vote == True]

incomeNew = replaceOutlier(training_data.monthlyincome, replace='minUpper')
incomeNew[:5]
training_data.monthlyincome = incomeNew

collections.Counter(training_data.numberoftimes90dayslate)
def removeSpecificAndPutMedian(data, first = 98, second = 96):
    New = []
    med = data.median()
    for val in data:
        if ((val == first) | (val == second)):
            New.append(med)
        else:
            New.append(val)
    return New

new = removeSpecificAndPutMedian(training_data.numberoftimes90dayslate)
training_data.numberoftimes90dayslate = new

collections.Counter(training_data.numberrealestateloansorlines)
realNew = []
for val in training_data.numberrealestateloansorlines:
    if val > 17:
        realNew.append(17)
    else:
        realNew.append(val)
training_data.numberrealestateloansorlines = realNew
collections.Counter(training_data.numberoftime6089dayspastduenotworse)
new = removeSpecificAndPutMedian(training_data.numberoftime6089dayspastduenotworse)
training_data.numberoftime6089dayspastduenotworse = new
collections.Counter(training_data.numberofdependents)
depNew = []
for var in training_data.numberofdependents:
    if var > 10:
        depNew.append(10)
    else:
        depNew.append(var)
training_data.numberofdependents = depNew

#Till now we have detected and replaced the outliers with median/mean value ;mostly just by looking at the Count of each value
# also the box plot or other graphical methods; Now Lets move to find out Feature/Column Importance and
# Lets try to select only required columns;Using Random Forrest algorithms;

training_data.head()
#Get Feature Importance;
from sklearn.ensemble import RandomForestClassifier
training_data.columns[1:]
X = training_data.drop('seriousdlqin2yrs',axis=1)
y = training_data.seriousdlqin2yrs
features_lables = training_data.columns[1:]
forrest = RandomForestClassifier(n_estimators = 1000,random_state = 0, n_jobs = 1)
forrest.fit(X,y)
importances = forrest.feature_importances_
indices = (np.argsort(importances))[::-1]

for i in range(X.shape[1]):
    print ("%2d) %-*s %f" % (i + 1, 30, features_lables[i],importances[indices[i]]))
plt.title('Feature Importances')
plt.bar(range(X.shape[1]),importances[indices], color="green", align="center")
plt.xticks(range(X.shape[1]),features_lables, rotation=90)
plt.xlim([-1, X.shape[1]])
plt.show()
#### Train and build the Baseine Model now;
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score

X = training_data.drop("seriousdlqin2yrs",axis=1)
y = training_data.seriousdlqin2yrs
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
knMod = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2,
                             metric='minkowski', metric_params=None)
X_test.shape
knMod.fit(X_train, y_train)
knMod.score(X_test,y_test)
test_labels=knMod.predict_proba(np.array(X_test.values))[:,1]
roc_auc_score(y_test,test_labels , average='macro', sample_weight=None)
glmMod = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=1.0, fit_intercept=True,
                            intercept_scaling=1, class_weight=None,
                            random_state=None, solver='liblinear', max_iter=100,
                            multi_class='ovr', verbose=2)
glmMod.fit(X_train, y_train)
glmMod.score(X_test, y_test)
test_labels=glmMod.predict_proba(np.array(X_test.values))[:,1]
roc_auc_score(y_test,test_labels , average='macro', sample_weight=None)

adaMod = AdaBoostClassifier(base_estimator=None, n_estimators=200, learning_rate=1.0)
adaMod.fit(X_train, y_train)
adaMod.score(X_test, y_test)
test_labels=adaMod.predict_proba(np.array(X_test.values))[:,1]
roc_auc_score(y_test,test_labels , average='macro', sample_weight=None)

gbMod = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=1.0,
                                   min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,
                                   max_depth=3,
                                   init=None, random_state=None, max_features=None, verbose=0)


gbMod.fit(X_train,y_train)
test_labels=gbMod.predict_proba(np.array(X_test.values))[:,1]
roc_auc_score(y_test,test_labels , average='macro', sample_weight=None)

rfMod = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2,
                               min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',
                               max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1,
                               random_state=None, verbose=0)

rfMod.fit(X_train, y_train)
rfMod.score(X_test, y_test)
test_labels=rfMod.predict_proba(np.array(X_test.values))[:,1]
roc_auc_score(y_test,test_labels , average='macro', sample_weight=None)

## Here we can see that we got two classifiers who has AUC score good : AdaBoostClassifier and GradientBoostingClassifier;
#But still we need to if our dataset is not overfitted to the algorithm;
# We then try for cross validation technique; and we will check if we can tune the Parameters of the algorithm;
# ie tuning for Hyperparameters;

from sklearn.model_selection import cross_val_score
def cvDictGen(functions, scr, X_train=X, y_train=y, cv=5, verbose=1):
    cvDict = {}
    for func in functions:
        cvScore = cross_val_score(func, X_train, y_train, cv=cv, verbose=verbose, scoring=scr)
        cvDict[str(func).split('(')[0]] = [cvScore.mean(), cvScore.std()]
    return cvDict

cvD = cvDictGen(functions=[knMod, glmMod, adaMod, gbMod, rfMod], scr='roc_auc')

###Hyper parameter optimization using Randomized search
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

#AdaBoost
adaHyperParams = {'n_estimators': [10,50,100,200,420]}
gridSearchAda = RandomizedSearchCV(estimator=adaMod, param_distributions=adaHyperParams, n_iter=5,scoring='roc_auc', cv=None, verbose=2).fit(X_train, y_train)

gridSearchAda.best_params_, gridSearchAda.best_score_

# GradientBoostingClassifier
gbHyperParams = {'loss' : ['deviance', 'exponential'],
                 'n_estimators': randint(10, 500),
                 'max_depth': randint(1,10)}
gridSearchGB = RandomizedSearchCV(estimator=gbMod, param_distributions=gbHyperParams, n_iter=10,
                                   scoring='roc_auc',  cv=None, verbose=2).fit(X_train, y_train)

gridSearchGB.best_params_,gridSearchGB.best_score_

bestGbModFitted = gridSearchGB.best_estimator_.fit(X_train, y_train)
bestAdaModFitted = gridSearchAda.best_estimator_.fit(X_train, y_train)
cvDictbestpara = cvDictGen(functions=[bestGbModFitted, bestAdaModFitted], scr='roc_auc')
cvDictbestpara

test_labels=bestGbModFitted.predict_proba(np.array(X_test.values))[:,1]
roc_auc_score(y_test,test_labels , average='macro', sample_weight=None)
test_labels=bestAdaModFitted.predict_proba(np.array(X_test.values))[:,1]
roc_auc_score(y_test,test_labels , average='macro', sample_weight=None)

import numpy as np
from sklearn.preprocessing import FunctionTransformer

transformer = FunctionTransformer(np.log1p)
X_train_1 = np.array(X_train)
X_train_transform = transformer.transform(X_train_1)
bestGbModFitted_transformed = gridSearchGB.best_estimator_.fit(X_train_transform, y_train)
bestAdaModFitted_transformed = gridSearchAda.best_estimator_.fit(X_train_transform, y_train)
cvDictbestpara_transform = cvDictGen(functions=[bestGbModFitted_transformed, bestAdaModFitted_transformed],
                                     scr='roc_auc')

cvDictbestpara_transform
import numpy as np
from sklearn.preprocessing import FunctionTransformer

transformer = FunctionTransformer(np.log1p)
X_test_1 = np.array(X_test)
X_test_transform = transformer.transform(X_test_1)


X_test_transform
test_labels=bestGbModFitted_transformed.predict_proba(np.array(X_test_transform))[:,1]
roc_auc_score(y_test,test_labels , average='macro', sample_weight=None)

test_labels=bestAdaModFitted_transformed.predict_proba(np.array(X_test_transform))[:,1]
roc_auc_score(y_test,test_labels , average='macro', sample_weight=None)

#Voting based Ensamble models ;
from sklearn.ensemble import VotingClassifier
votingMod = VotingClassifier(estimators=[('gb', bestGbModFitted_transformed),
                                         ('ada', bestAdaModFitted_transformed)], voting='soft',weights=[2,1])

votingMod = votingMod.fit(X_train_transform, y_train)
test_labels=votingMod.predict_proba(np.array(X_test_transform))[:,1]
votingMod.score(X_test_transform, y_test)
roc_auc_score(y_test,test_labels , average='macro', sample_weight=None)

#Testing on Real Test Dataset
test_data = pd.read_csv('./data/cs-test.csv').drop('Unnamed: 0', axis = 1)
cleancolumn = []
for i in range(len(test_data.columns)):
    cleancolumn.append(test_data.columns[i].replace('-', '').lower())
test_data.columns = cleancolumn

test_data.drop(['seriousdlqin2yrs'], axis=1, inplace=True)
test_data.fillna((training_data.median()), inplace=True)
test_data.head()
test_labels_votingMod_old = votingMod.predict_proba(np.array(test_data.values))[:,1]
test_labels_votingMod_old.shape
output = pd.DataFrame({'ID':test_data.index, 'probability':test_labels_votingMod_old})
output.to_csv("./predictions.csv", index=False)
output.head()
